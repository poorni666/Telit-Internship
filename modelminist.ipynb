{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbsreEfjnQtP"
      },
      "source": [
        "# Implementation of MobileNetv2+SSD<br>\n",
        "This is an implementation of the MobileNetv2 + SSD architecture for a relatively simpler task of determining bounding boxes for MNIST images embedded in a box. Each box contains only one digit(28x28 MNIST embedded into a 224x224 box) as of now, but the number of predictions per image can be expanded easily (the training outputs need to modified). Also, no data augmentation has been used till now (Colab kept crashing when I increased the dataset size beyond 1000, so the initial amount of data present was sufficient. The crashes might have been due to high traffic, but I haven't confirmed it).<p>\n",
        "In the earlier implementation, the ground truth data contained information about only one bounding box, which meant only one prediction per image (reference in README). For me, it also reduced the training signal and the model was overfitting. So I changed the outputs to a prediction for each default box (as it should be, from what I understood from the SSD paper). Although the initial implementation is good for the purposes for understanding the model.\n",
        "\n",
        "Comments mentioned throughout the code mention what needs to change if the model inputs or outputs are changed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdL2AL8yAi00"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qumy7Fegdc6L",
        "outputId": "9f5fa69a-91f9-4c2d-fdfd-fc9887912b1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: keras==2.8 in /home/poornimadevikr/.local/lib/python3.7/site-packages (2.8.0)\n",
            "Requirement already satisfied: bottleneck in /home/poornimadevikr/.local/lib/python3.7/site-packages (1.4.0)\n",
            "Requirement already satisfied: numpy in /home/poornimadevikr/.local/lib/python3.7/site-packages (from bottleneck) (1.21.6)\n",
            "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
            "You should consider upgrading via the '/opt/pyenv/versions/3.7.13/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install keras==2.8 bottleneck"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.7.13\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_hvSY3X-AeFP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras \n",
        "import tensorflow as tf\n",
        "import numpy.matlib\n",
        "from PIL import Image\n",
        "from keras import backend as K\n",
        "from scipy.special import softmax\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import bottleneck"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3wFty_P6dfBB"
      },
      "outputs": [],
      "source": [
        "tf.compat.v1.disable_eager_execution()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFmrlFJ8uKCe"
      },
      "source": [
        "Define Bottleneck Residual layer for MobileNet<br>\n",
        "Using the same parameters as mentioned in the paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xmwhyyS7CFyK"
      },
      "outputs": [],
      "source": [
        "class Bottleneck(keras.Model):\n",
        "  def __init__(\n",
        "      self,\n",
        "      expansion,\n",
        "      stride,\n",
        "      block_id,\n",
        "      filters,\n",
        "      alpha=1,\n",
        "      ):\n",
        "    super(Bottleneck,self).__init__(name = \"Bottleneck_\" + block_id)\n",
        "    self.stride = stride\n",
        "    self.expansion = expansion\n",
        "    self.alpha = alpha\n",
        "    self.output_channels = self.alpha * filters\n",
        "    self.out = None # there was some problem with the eager execution\n",
        "\n",
        "    prefix =  'Bottleneck_{}_'.format(block_id)\n",
        "    self.prefix = prefix\n",
        "    # expansion\n",
        "    self.expand_BN = layers.BatchNormalization(name = prefix + 'expand_BN')\n",
        "    self.expand_ReLU = layers.ReLU(max_value=6, name = prefix + 'expand_ReLU')\n",
        "\n",
        "    #conv\n",
        "    self.Conv = layers.DepthwiseConv2D(\n",
        "        kernel_size = 3,\n",
        "        padding='same',\n",
        "        strides = self.stride,\n",
        "        use_bias = False,\n",
        "        name = prefix + 'conv')\n",
        "    self.Conv_BN = layers.BatchNormalization(name = prefix + 'conv_BN')\n",
        "    self.Conv_ReLU = layers.ReLU(max_value=6, name = prefix + 'conv_ReLU')\n",
        "\n",
        "    #project\n",
        "    self.project = layers.Conv2D(\n",
        "        filters = self.output_channels,\n",
        "        kernel_size = 1,\n",
        "        use_bias = False,\n",
        "        name = 'contract')\n",
        "    self.project_BN = layers.BatchNormalization(name = prefix + 'contract_BN')\n",
        "\n",
        "    # dimensions need to be the same for residual connection\n",
        "    self.residual = layers.Add(name=prefix + 'residual')\n",
        "  \n",
        "  def build(self, input_shape):\n",
        "    self.d = input_shape[-1]\n",
        "    \n",
        "    self.expand = layers.Conv2D(\n",
        "        filters = self.expansion*self.d,\n",
        "        kernel_size = 1,\n",
        "        use_bias = False,\n",
        "        name = self.prefix+'expand')\n",
        "\n",
        "      \n",
        "  def call(self, inputs):\n",
        "\n",
        "    x = self.expand(inputs)\n",
        "    x = self.expand_BN(x)\n",
        "    x = self.expand_ReLU(x)\n",
        "    self.out = x\n",
        "    \n",
        "    x = self.Conv(x)\n",
        "    x = self.Conv_BN(x)\n",
        "    x = self.Conv_ReLU(x)\n",
        "\n",
        "    x = self.project(x)\n",
        "    x = self.project_BN(x)\n",
        "\n",
        "    if self.output_channels == self.d and self.stride == 1:\n",
        "      x = self.residual([inputs,x])\n",
        "\n",
        "    return x\n",
        "\n",
        "  def model(self):\n",
        "      x = keras.Input(shape=(28,28,3))\n",
        "      return keras.Model(inputs=[x], outputs=self.call(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfMYYpWpuQj4"
      },
      "source": [
        "Define MobileNetv2<br>\n",
        "Same components as mentioned in the paper (the input image dimensions are a bit different)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VYGagWE8T2Et"
      },
      "outputs": [],
      "source": [
        "#using the architecture mentioned in the paper\n",
        "class MobileNetv2(keras.Model):\n",
        "  def __init__(self, k = 11):\n",
        "    super(MobileNetv2,self).__init__()\n",
        "    self.conv_inp = layers.Conv2D(\n",
        "        filters = 32,\n",
        "        kernel_size = 3,\n",
        "        strides = (2,2),\n",
        "        padding='valid',\n",
        "        use_bias = False,\n",
        "        name = 'conv'\n",
        "    )\n",
        "    self.k = k    \n",
        "\n",
        "    self.pad = layers.ZeroPadding2D(padding=2,name='pad')\n",
        "    self.BN = layers.BatchNormalization(name='BN')\n",
        "    self.ReLU = layers.ReLU(max_value = 6, name = 'ReLU')\n",
        "    \n",
        "    self.B1_1 = Bottleneck(expansion = 1, filters = 16, stride = 1, block_id = 'B1_1')\n",
        "\n",
        "    self.B2_1 = Bottleneck(expansion = 6, filters = 24, stride = 2, block_id = 'B2_1')\n",
        "    self.B2_2 = Bottleneck(expansion = 6, filters = 24, stride = 1, block_id = 'B2_2')\n",
        "\n",
        "    self.B3_1 = Bottleneck(expansion = 6, filters = 32, stride = 2, block_id = 'B3_1')\n",
        "    self.B3_2 = Bottleneck(expansion = 6, filters = 32, stride = 1, block_id = 'B3_2')\n",
        "    self.B3_3 = Bottleneck(expansion = 6, filters = 32, stride = 1, block_id = 'B3_3')\n",
        "\n",
        "    self.B4_1 = Bottleneck(expansion = 6, filters = 64, stride = 2, block_id = 'B4_1')\n",
        "    self.B4_2 = Bottleneck(expansion = 6, filters = 64, stride = 1, block_id = 'B4_2')\n",
        "    self.B4_3 = Bottleneck(expansion = 6, filters = 64, stride = 1, block_id = 'B4_3')\n",
        "    self.B4_4 = Bottleneck(expansion = 6, filters = 64, stride = 1, block_id = 'B4_4')\n",
        "\n",
        "    self.B5_1 = Bottleneck(expansion = 6, filters = 96, stride = 1, block_id = 'B5_1')\n",
        "    self.B5_2 = Bottleneck(expansion = 6, filters = 96, stride = 1, block_id = 'B5_2')\n",
        "    self.B5_3 = Bottleneck(expansion = 6, filters = 96, stride = 1, block_id = 'B5_3')\n",
        "\n",
        "    self.B6_1 = Bottleneck(expansion = 6, filters = 160, stride = 2, block_id = 'B6_1')\n",
        "    self.B6_2 = Bottleneck(expansion = 6, filters = 160, stride = 1, block_id = 'B6_2')\n",
        "    self.B6_3 = Bottleneck(expansion = 6, filters = 160, stride = 1, block_id = 'B6_3')\n",
        "\n",
        "    self.B7_1 = Bottleneck(expansion = 6, filters = 320, stride = 1, block_id = 'B7_1')\n",
        "\n",
        "    self.conv_out = layers.Conv2D(\n",
        "        filters = 1280,\n",
        "        kernel_size = 1,\n",
        "        strides = (1,1),\n",
        "        use_bias = False,\n",
        "        name = 'conv_out'\n",
        "    )\n",
        "    self.avgpool = layers.AveragePooling2D(\n",
        "        pool_size = (7,7),\n",
        "        name='avg_pool'\n",
        "        )\n",
        "    \n",
        "    self.conv_seg = layers.Conv2D(\n",
        "        filters = self.k,\n",
        "        kernel_size = 1,\n",
        "        strides = (1,1),\n",
        "        use_bias = False,\n",
        "        name = 'conv_seg'\n",
        "    )\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = self.conv_inp(inputs)\n",
        "    x = self.BN(x)\n",
        "    x = self.ReLU(x)\n",
        "\n",
        "    x = self.B1_1(x)\n",
        "    x = self.B2_1(x)\n",
        "    x = self.B2_2(x)\n",
        "\n",
        "    x = self.B3_1(x)\n",
        "    x = self.B3_2(x)\n",
        "    x = self.B3_3(x)\n",
        "    \n",
        "    x = self.B4_1(x)\n",
        "    x = self.B4_2(x)\n",
        "    x = self.B4_3(x)\n",
        "    x = self.B4_4(x)\n",
        "    \n",
        "    x = self.B5_1(x)\n",
        "    x = self.B5_2(x)\n",
        "    x = self.B5_3(x)\n",
        "    \n",
        "    x = self.B6_1(x)\n",
        "    x = self.B6_2(x)\n",
        "    x = self.B6_3(x)\n",
        "    \n",
        "    x = self.B7_1(x)\n",
        "\n",
        "    x = self.conv_out(x)\n",
        "    x = self.avgpool(x)\n",
        "    c4 = self.conv_seg(x)\n",
        "\n",
        "    return c4\n",
        "\n",
        "  def model(self):\n",
        "      x = keras.Input(shape=(224,224,3))\n",
        "\n",
        "      return keras.Model(inputs=x, outputs=self.call(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05i7363EYwmP",
        "outputId": "a1d0ed91-6aff-4bdd-c04e-f2ca01ea3cad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /home/poornimadevikr/git/mymodels/MobileNetv2-SSD/.venvssd/lib/python3.7/site-packages/keras/layers/normalization/batch_normalization.py:532: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " conv (Conv2D)               (None, 111, 111, 32)      864       \n",
            "                                                                 \n",
            " BN (BatchNormalization)     (None, 111, 111, 32)      128       \n",
            "                                                                 \n",
            " ReLU (ReLU)                 (None, 111, 111, 32)      0         \n",
            "                                                                 \n",
            " Bottleneck_B1_1 (Bottleneck  (None, 111, 111, 16)     2144      \n",
            " )                                                               \n",
            "                                                                 \n",
            " Bottleneck_B2_1 (Bottleneck  (None, 56, 56, 24)       5568      \n",
            " )                                                               \n",
            "                                                                 \n",
            " Bottleneck_B2_2 (Bottleneck  (None, 56, 56, 24)       9456      \n",
            " )                                                               \n",
            "                                                                 \n",
            " Bottleneck_B3_1 (Bottleneck  (None, 28, 28, 32)       10640     \n",
            " )                                                               \n",
            "                                                                 \n",
            " Bottleneck_B3_2 (Bottleneck  (None, 28, 28, 32)       15680     \n",
            " )                                                               \n",
            "                                                                 \n",
            " Bottleneck_B3_3 (Bottleneck  (None, 28, 28, 32)       15680     \n",
            " )                                                               \n",
            "                                                                 \n",
            " Bottleneck_B4_1 (Bottleneck  (None, 14, 14, 64)       21952     \n",
            " )                                                               \n",
            "                                                                 \n",
            " Bottleneck_B4_2 (Bottleneck  (None, 14, 14, 64)       55936     \n",
            " )                                                               \n",
            "                                                                 \n",
            " Bottleneck_B4_3 (Bottleneck  (None, 14, 14, 64)       55936     \n",
            " )                                                               \n",
            "                                                                 \n",
            " Bottleneck_B4_4 (Bottleneck  (None, 14, 14, 64)       55936     \n",
            " )                                                               \n",
            "                                                                 \n",
            " Bottleneck_B5_1 (Bottleneck  (None, 14, 14, 96)       68352     \n",
            " )                                                               \n",
            "                                                                 \n",
            " Bottleneck_B5_2 (Bottleneck  (None, 14, 14, 96)       120768    \n",
            " )                                                               \n",
            "                                                                 \n",
            " Bottleneck_B5_3 (Bottleneck  (None, 14, 14, 96)       120768    \n",
            " )                                                               \n",
            "                                                                 \n",
            " Bottleneck_B6_1 (Bottleneck  (None, 7, 7, 160)        157888    \n",
            " )                                                               \n",
            "                                                                 \n",
            " Bottleneck_B6_2 (Bottleneck  (None, 7, 7, 160)        324160    \n",
            " )                                                               \n",
            "                                                                 \n",
            " Bottleneck_B6_3 (Bottleneck  (None, 7, 7, 160)        324160    \n",
            " )                                                               \n",
            "                                                                 \n",
            " Bottleneck_B7_1 (Bottleneck  (None, 7, 7, 320)        478400    \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_out (Conv2D)           (None, 7, 7, 1280)        409600    \n",
            "                                                                 \n",
            " avg_pool (AveragePooling2D)  (None, 1, 1, 1280)       0         \n",
            "                                                                 \n",
            " conv_seg (Conv2D)           (None, 1, 1, 11)          14080     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,268,096\n",
            "Trainable params: 2,236,480\n",
            "Non-trainable params: 31,616\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "MobileNetv2().model().summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "II03ZRu17FnE"
      },
      "source": [
        "Defining SSD<br>\n",
        "The default number of boxes per layer and resolution of each layer is different, since we are working with MNIST data and 224x224 image sizes.<p>\n",
        "To change the number of boxes per layer and layerWidths, some constraints need to be kept in mind which are mentioned in the later sections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aYD2gfR9O8L0"
      },
      "outputs": [],
      "source": [
        "class SSD(keras.Model):\n",
        "  def __init__(self, numBoxes=[4,6,6,6,4,4], layerWidth=[28,14,7,4,2,1], k = 10+1+4):\n",
        "    super(SSD,self).__init__()\n",
        "    self.classes = k\n",
        "    self.featureMaps = 6\n",
        "    self.MobileNet = MobileNetv2(k=k)\n",
        "\n",
        "    # mark bottleneck_6_1 onwards as non trainable\n",
        "    for layer in self.MobileNet.layers[-7:]:\n",
        "      layer.trainable=False\n",
        "    \n",
        "    # For bottleneck_5_3, mark layers beyond conv as non runnable\n",
        "    # layers in bottleneck_5_3: ['Bottleneck_B5_3_expand_BN', 'Bottleneck_B5_3_expand_ReLU', 'Bottleneck_B5_3_conv', 'Bottleneck_B5_3_conv_BN', \n",
        "    # 'Bottleneck_B5_3_conv_ReLU', 'contract', 'Bottleneck_B5_3_contract_BN', 'Bottleneck_B5_3_residual', 'Bottleneck_B5_3_expand']\n",
        "    for layer in self.MobileNet.layers[-8].layers[2:-1]:\n",
        "      layer.trainable=False\n",
        "\n",
        "    self.numBoxes = numBoxes\n",
        "    self.layerWidth = layerWidth\n",
        "    self.features = [None for _ in range(self.featureMaps)]\n",
        "    self.classifiers = [None for _ in range(self.featureMaps)]\n",
        "    \n",
        "    self.conv1_1 = layers.Conv2D(256,1,name='SSD_conv_1_1')\n",
        "    self.conv1_2 = layers.Conv2D(512,3,strides=(2,2),padding='same',name='SSD_conv_1_2')\n",
        "\n",
        "    self.conv2_1 = layers.Conv2D(128,1,name='SSD_conv_2_1')\n",
        "    self.conv2_2 = layers.Conv2D(256,3,strides=(2,2),padding='same',name='SSD_conv_2_2')\n",
        "    \n",
        "    self.conv3_1 = layers.Conv2D(128,1,name='SSD_conv_3_1')\n",
        "    self.conv3_2 = layers.Conv2D(256,3,strides=(1,1),name='SSD_conv_3_2')\n",
        "    \n",
        "    self.conv4_1 = layers.Conv2D(128,1,name='SSD_conv_4_1')\n",
        "    self.conv4_2 = layers.Conv2D(256,2,strides=(1,1),name='SSD_conv_4_2') # changed the kernel size to 2 since the output of the previous layer has width 3\n",
        "\n",
        "    self.conv = []\n",
        "    self.reshape = []\n",
        "    for i in range(self.featureMaps):\n",
        "      self.conv.append(layers.Conv2D(self.numBoxes[i]*self.classes,3,padding='same',name='Classification_'+str(i)))\n",
        "      self.reshape.append(layers.Reshape((self.layerWidth[i]* self.layerWidth[i] * self.numBoxes[i],self.classes),name='Reshape_classification_'+str(i)))\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.MobileNet.build(input_shape)\n",
        "  \n",
        "  def call(self,inputs):\n",
        "    x = inputs\n",
        "    x = self.MobileNet(x)\n",
        "\n",
        "    # get the convolved images at different resolutions\n",
        "    self.features[0] = self.MobileNet.get_layer('Bottleneck_B4_1').out\n",
        "    self.features[1] = self.MobileNet.get_layer('Bottleneck_B5_3').out\n",
        "    self.features[2] = self.conv1_2(self.conv1_1(self.features[1]))\n",
        "    self.features[3] = self.conv2_2(self.conv2_1(self.features[2]))\n",
        "    self.features[4] = self.conv3_2(self.conv3_1(self.features[3]))\n",
        "    self.features[5] = self.conv4_2(self.conv4_1(self.features[4]))\n",
        "\n",
        "    for i in range(self.featureMaps):\n",
        "    # for each feature map, create predictions according to the number of boxes for that layer and the number of output channels\n",
        "      x = self.conv[i](self.features[i])\n",
        "      x = self.reshape[i](x)\n",
        "      self.classifiers[i] = x\n",
        "    \n",
        "    # concatenate all the classifiers\n",
        "    x = layers.concatenate(self.classifiers, axis = -2, name='concatenate')\n",
        "    return x\n",
        "\n",
        "\n",
        "  def model(self):\n",
        "      x = keras.Input(shape=(224,224,3))\n",
        "\n",
        "      return keras.Model(inputs=x, outputs=self.call(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "29A_FW-GxK4t"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 10\n",
        "# the first 2 dimensions should be equal to width of the output from the bottleneck expand ReLU at the (4,1) and (5,3) respectively.\n",
        "# the dimensions after the second one are determined by the convolutions written inside the SSD (conv1_2, conv2_2, conv3_3, conv4_2)\n",
        "layerWidths = [28,14,7,4,2,1]\n",
        "numBoxes = [3,3,3,3,3,3]\n",
        "assert len(numBoxes) == len(layerWidths) # numBoxes for each layer and each layer has a specific width\n",
        "outputChannels = NUM_CLASSES + 1 + 4 # 10 classes + background + cx,cy,h,w\n",
        "assert outputChannels - NUM_CLASSES == 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmOfPVIjCkuP",
        "outputId": "16c53e83-aa54-44c8-bd30-43d452cce1c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv (Conv2D)                  (None, 111, 111, 32  864         ['input_2[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " BN (BatchNormalization)        (None, 111, 111, 32  128         ['conv[0][0]']                   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " ReLU (ReLU)                    (None, 111, 111, 32  0           ['BN[0][0]']                     \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Bottleneck_B1_1 (Bottleneck)   (None, 111, 111, 16  2144        ['ReLU[0][0]']                   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Bottleneck_B2_1 (Bottleneck)   (None, 56, 56, 24)   5568        ['Bottleneck_B1_1[0][0]']        \n",
            "                                                                                                  \n",
            " Bottleneck_B2_2 (Bottleneck)   (None, 56, 56, 24)   9456        ['Bottleneck_B2_1[0][0]']        \n",
            "                                                                                                  \n",
            " Bottleneck_B3_1 (Bottleneck)   (None, 28, 28, 32)   10640       ['Bottleneck_B2_2[0][0]']        \n",
            "                                                                                                  \n",
            " Bottleneck_B3_2 (Bottleneck)   (None, 28, 28, 32)   15680       ['Bottleneck_B3_1[0][0]']        \n",
            "                                                                                                  \n",
            " Bottleneck_B3_3 (Bottleneck)   (None, 28, 28, 32)   15680       ['Bottleneck_B3_2[0][0]']        \n",
            "                                                                                                  \n",
            " Bottleneck_B4_1 (Bottleneck)   (None, 14, 14, 64)   21952       ['Bottleneck_B3_3[0][0]']        \n",
            "                                                                                                  \n",
            " Bottleneck_B4_2 (Bottleneck)   (None, 14, 14, 64)   55936       ['Bottleneck_B4_1[0][0]']        \n",
            "                                                                                                  \n",
            " Bottleneck_B4_3 (Bottleneck)   (None, 14, 14, 64)   55936       ['Bottleneck_B4_2[0][0]']        \n",
            "                                                                                                  \n",
            " Bottleneck_B4_4 (Bottleneck)   (None, 14, 14, 64)   55936       ['Bottleneck_B4_3[0][0]']        \n",
            "                                                                                                  \n",
            " Bottleneck_B5_1 (Bottleneck)   (None, 14, 14, 96)   68352       ['Bottleneck_B4_4[0][0]']        \n",
            "                                                                                                  \n",
            " Bottleneck_B5_2 (Bottleneck)   (None, 14, 14, 96)   120768      ['Bottleneck_B5_1[0][0]']        \n",
            "                                                                                                  \n",
            " Bottleneck_B5_3_expand (Conv2D  (None, 14, 14, 576)  55296      ['Bottleneck_B5_2[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " Bottleneck_B5_3_expand_BN (Bat  (None, 14, 14, 576)  2304       ['Bottleneck_B5_3_expand[0][0]'] \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " Bottleneck_B5_3_expand_ReLU (R  (None, 14, 14, 576)  0          ['Bottleneck_B5_3_expand_BN[0][0]\n",
            " eLU)                                                            ']                               \n",
            "                                                                                                  \n",
            " SSD_conv_1_1 (Conv2D)          (None, 14, 14, 256)  147712      ['Bottleneck_B5_3_expand_ReLU[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " SSD_conv_1_2 (Conv2D)          (None, 7, 7, 512)    1180160     ['SSD_conv_1_1[0][0]']           \n",
            "                                                                                                  \n",
            " SSD_conv_2_1 (Conv2D)          (None, 7, 7, 128)    65664       ['SSD_conv_1_2[0][0]']           \n",
            "                                                                                                  \n",
            " SSD_conv_2_2 (Conv2D)          (None, 4, 4, 256)    295168      ['SSD_conv_2_1[0][0]']           \n",
            "                                                                                                  \n",
            " SSD_conv_3_1 (Conv2D)          (None, 4, 4, 128)    32896       ['SSD_conv_2_2[0][0]']           \n",
            "                                                                                                  \n",
            " Bottleneck_B4_1_expand (Conv2D  (None, 28, 28, 192)  6144       ['Bottleneck_B3_3[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " SSD_conv_3_2 (Conv2D)          (None, 2, 2, 256)    295168      ['SSD_conv_3_1[0][0]']           \n",
            "                                                                                                  \n",
            " Bottleneck_B4_1_expand_BN (Bat  (None, 28, 28, 192)  768        ['Bottleneck_B4_1_expand[0][0]'] \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " SSD_conv_4_1 (Conv2D)          (None, 2, 2, 128)    32896       ['SSD_conv_3_2[0][0]']           \n",
            "                                                                                                  \n",
            " Bottleneck_B4_1_expand_ReLU (R  (None, 28, 28, 192)  0          ['Bottleneck_B4_1_expand_BN[0][0]\n",
            " eLU)                                                            ']                               \n",
            "                                                                                                  \n",
            " SSD_conv_4_2 (Conv2D)          (None, 1, 1, 256)    131328      ['SSD_conv_4_1[0][0]']           \n",
            "                                                                                                  \n",
            " Classification_0 (Conv2D)      (None, 28, 28, 45)   77805       ['Bottleneck_B4_1_expand_ReLU[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " Classification_1 (Conv2D)      (None, 14, 14, 45)   233325      ['Bottleneck_B5_3_expand_ReLU[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " Classification_2 (Conv2D)      (None, 7, 7, 45)     207405      ['SSD_conv_1_2[0][0]']           \n",
            "                                                                                                  \n",
            " Classification_3 (Conv2D)      (None, 4, 4, 45)     103725      ['SSD_conv_2_2[0][0]']           \n",
            "                                                                                                  \n",
            " Classification_4 (Conv2D)      (None, 2, 2, 45)     103725      ['SSD_conv_3_2[0][0]']           \n",
            "                                                                                                  \n",
            " Classification_5 (Conv2D)      (None, 1, 1, 45)     103725      ['SSD_conv_4_2[0][0]']           \n",
            "                                                                                                  \n",
            " Reshape_classification_0 (Resh  (None, 2352, 15)    0           ['Classification_0[0][0]']       \n",
            " ape)                                                                                             \n",
            "                                                                                                  \n",
            " Reshape_classification_1 (Resh  (None, 588, 15)     0           ['Classification_1[0][0]']       \n",
            " ape)                                                                                             \n",
            "                                                                                                  \n",
            " Reshape_classification_2 (Resh  (None, 147, 15)     0           ['Classification_2[0][0]']       \n",
            " ape)                                                                                             \n",
            "                                                                                                  \n",
            " Reshape_classification_3 (Resh  (None, 48, 15)      0           ['Classification_3[0][0]']       \n",
            " ape)                                                                                             \n",
            "                                                                                                  \n",
            " Reshape_classification_4 (Resh  (None, 12, 15)      0           ['Classification_4[0][0]']       \n",
            " ape)                                                                                             \n",
            "                                                                                                  \n",
            " Reshape_classification_5 (Resh  (None, 3, 15)       0           ['Classification_5[0][0]']       \n",
            " ape)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 3150, 15)     0           ['Reshape_classification_0[0][0]'\n",
            "                                                                 , 'Reshape_classification_1[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'Reshape_classification_2[0][0]'\n",
            "                                                                 , 'Reshape_classification_3[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'Reshape_classification_4[0][0]'\n",
            "                                                                 , 'Reshape_classification_5[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,507,342\n",
            "Trainable params: 3,492,494\n",
            "Non-trainable params: 14,848\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = SSD(numBoxes=numBoxes, layerWidth=layerWidths, k = outputChannels)\n",
        "model.model().summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RA7NxfQ7_G6"
      },
      "source": [
        "Creating boxes and IoU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yRYi7Ez7UzpH"
      },
      "outputs": [],
      "source": [
        "# I have used less varying custom scales and aspect ratios here, since the dataset is already uniform\n",
        "#IMPORTANT: before changing the scales and aspect ratios, read the comment below\n",
        "\n",
        "# number of scales is equal to the number of different resolutions ie num of layer widths\n",
        "# for a given resolution, we have different aspect ratios\n",
        "# num(scales) = num(layerWidth) = num(numBoxes) and num(asp_ratios) = numBoxes[i]\n",
        "MinScale = .1 # Min and Max scale given as percentage\n",
        "MaxScale = 1.5\n",
        "scales = [ MinScale + x/len(layerWidths) * (MaxScale-MinScale) for x in range(len(layerWidths)) ]\n",
        "scales = scales[::-1] # reversing the order because the layerWidths go from high to low (lower to higher resoltuion)\n",
        "\n",
        "asp = [0.5,1.0,1.5]\n",
        "asp1 = [x**0.5 for x in asp]\n",
        "asp2 = [1/x for x in asp1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "RwR_TIbzYCix"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA_IhnyrUl4S",
        "outputId": "59f0db0d-5f22-4ee8-abd7-0a9d19b43e11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3150\n"
          ]
        }
      ],
      "source": [
        "# should be equal to the 1st dimension in the output layer of the SSD model\n",
        "BOXES = sum([a*a*b for a,b in zip(layerWidths,numBoxes)])\n",
        "centres = np.zeros((BOXES,2))\n",
        "hw = np.zeros((BOXES,2))\n",
        "boxes = np.zeros((BOXES,4))\n",
        "print(BOXES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9A1xGMrXVX18"
      },
      "outputs": [],
      "source": [
        "# calculating the default box centres and height, width\n",
        "idx = 0\n",
        "\n",
        "for gridSize, numBox, scale in zip(layerWidths,numBoxes,scales):\n",
        "  step_size = IMG_SIZE*1.0/gridSize\n",
        "  for i in range(gridSize):\n",
        "    for j in range(gridSize):\n",
        "      pos = idx + (i*gridSize+j) * numBox\n",
        "      # centre is the same for all aspect ratios(=numBox)\n",
        "      centres[ pos : pos + numBox , :] = i*step_size + step_size/2, j*step_size + step_size/2\n",
        "      # height and width vary according to the scale and aspect ratio\n",
        "      # zip asepct ratios and then scale them by the scaling factor\n",
        "      hw[ pos : pos + numBox , :] = np.multiply(gridSize*scale, np.squeeze(np.dstack([asp1,asp2]),axis=0))[:numBox,:]\n",
        "\n",
        "  idx += gridSize*gridSize*numBox "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Xp9CrasJhGXI"
      },
      "outputs": [],
      "source": [
        "# (x,y) co-ordinates of top left and bottom right\n",
        "# This actually is not used anywhere. centres[] and hw[] are a good enough substitute\n",
        "boxes[:,0] = centres[:,0] - hw[:,0]/2\n",
        "boxes[:,1] = centres[:,1] - hw[:,1]/2\n",
        "boxes[:,2] = centres[:,0] + hw[:,0]/2\n",
        "boxes[:,3] = centres[:,1] + hw[:,1]/2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "TJSIPHPMh3N2"
      },
      "outputs": [],
      "source": [
        "# calculate IoU for a set of search boxes and default boxes\n",
        "def IoU(box1, box2):\n",
        "  box1 = box1.astype(np.float64)\n",
        "  box2 = box2.astype(np.float64)\n",
        "  # find the left and right co-ordinates of the edges. Min should be less than Max for non zero overlap\n",
        "  xmin = np.maximum(box1[:,0],box2[:,0])\n",
        "  xmax = np.minimum(box1[:,2],box2[:,2])\n",
        "  ymin = np.maximum(box1[:,1],box2[:,1])\n",
        "  ymax = np.minimum(box1[:,3],box2[:,3])\n",
        "\n",
        "  intersection = np.abs(np.maximum(xmax-xmin,0) * np.maximum(ymax-ymin,0))\n",
        "  boxArea1 = np.abs((box1[:,2] - box1[:,0]) * (box1[:,3] - box1[:,1]))\n",
        "  boxArea2 = np.abs((box2[:,2] - box2[:,0]) * (box2[:,3] - box2[:,1]))\n",
        "  unionArea = boxArea1 + boxArea2 - intersection\n",
        "  assert (unionArea > 0).all()\n",
        "  iou = intersection / unionArea\n",
        "\n",
        "  return iou"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "iOcpxxIQipbA"
      },
      "outputs": [],
      "source": [
        "# give the index of the box correpsonding to the IoUs > threshold (=0.5) \n",
        "def bestIoU(searchBox):\n",
        "  return np.argwhere(IoU(numpy.matlib.repmat(searchBox,BOXES,1), boxes) > 0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm2k4c5Ik_BX"
      },
      "source": [
        "Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "h07BGB7-k9te"
      },
      "outputs": [],
      "source": [
        "TRAINSIZE = 600\n",
        "TESTSIZE = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkZPTKgGq08N",
        "outputId": "48b663c1-2189-4bd9-bf3e-a2adf64c48dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "11501568/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = x_train[:TRAINSIZE , : , :]\n",
        "y_train = y_train[:TRAINSIZE]\n",
        "x_test = x_test[:TESTSIZE , : , :]\n",
        "y_test = y_test[:TESTSIZE]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "PEgx1Sdcq7yJ"
      },
      "outputs": [],
      "source": [
        "# take mnist x and y pairs and convert to input, output pairs for the MobileNetv2+SSD model\n",
        "def convert(x,y):\n",
        "  MNIST_SIZE = x.shape[-1]\n",
        "  # create a 2D array of top left corners for the mnist image to be placed\n",
        "  corner = np.random.randint(IMG_SIZE - MNIST_SIZE, size=(x.shape[0],2))\n",
        "\n",
        "  # create a blank canvas for the input with the required dimension\n",
        "  input = np.zeros((x.shape[0], IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "  # replacing a part by RGB version of MNIST\n",
        "  for i in range(x.shape[0]):\n",
        "    lx = int(corner[i,0])\n",
        "    ly = int(corner[i,1])\n",
        "    input[i,lx:lx + MNIST_SIZE, ly:ly+MNIST_SIZE,:] = np.repeat(np.expand_dims(np.array(x[i,:,:]),axis=-1),3,axis=-1)\n",
        "\n",
        "  # for each default box, there are 5 values: class number and delta cx,cy,h,w\n",
        "  output = np.zeros((y.shape[0],BOXES,1+4))\n",
        "  output[:,:,0] = NUM_CLASSES # defaulting class labels for all boxes to background initially\n",
        "  for i in range(x.shape[0]):\n",
        "    bbox = np.zeros(4)\n",
        "    bbox[:2] = corner[i]\n",
        "    bbox[2:] = corner[i] + (MNIST_SIZE,MNIST_SIZE)\n",
        "    # for all default boxes which have IoU > threshold, set the delta values and class number\n",
        "    box_idx = bestIoU(bbox).astype(np.uint16)\n",
        "    output[i,box_idx,0] = y[i]\n",
        "    output[i,box_idx,1] = (bbox[0] + bbox[2])/2.0 - centres[box_idx,0]\n",
        "    output[i,box_idx,2] = (bbox[1] + bbox[3])/2.0 - centres[box_idx,1]\n",
        "    output[i,box_idx,3] = MNIST_SIZE - hw[box_idx,0]\n",
        "    output[i,box_idx,4] = MNIST_SIZE - hw[box_idx,1]\n",
        "\n",
        "  return input, output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Sk_z17wV3Bj5"
      },
      "outputs": [],
      "source": [
        "test_x, test_y = convert(x_test,y_test)\n",
        "train_x, train_y = convert(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "NAwnJnu4qE0P",
        "outputId": "36105aba-89ce-4e12-ad01-2ab01a6b2785"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of boxes with IoU > threshold (0.5): 9\n",
            "Green box: ground truth. Red box: default boxes with IoU < threshold (0.5)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# checking if the inputs prepared are correct or not\n",
        "r = np.random.randint(0,train_x.shape[0])\n",
        "img = train_x[r,:,:,:].copy()\n",
        "img_y = train_y[r]\n",
        "\n",
        "im = np.array(Image.fromarray(img.astype(np.uint8)))\n",
        "fig,ax = plt.subplots(1)\n",
        "ax.imshow(im)\n",
        "\n",
        "# find all boxes where class label is not background\n",
        "idx = np.argwhere(img_y[:,0] != NUM_CLASSES)[:,0]\n",
        "print('Number of boxes with IoU > threshold (0.5):',idx.shape[0])\n",
        "print('Green box: ground truth. Red box: default boxes with IoU < threshold (0.5)')\n",
        "\n",
        "#calculating the ground truth bounding boxes\n",
        "gt = np.zeros(4,dtype=np.uint16)\n",
        "gt[:2] = (img_y[idx[0],1:3] + centres[idx[0],:2])\n",
        "gt[2:] = (img_y[idx[0],3:] + hw[idx[0],:])\n",
        "\n",
        "# for some reason, x and y are inverted\n",
        "rect = patches.Rectangle((gt[1]-gt[3]/2,gt[0]-gt[2]/2),gt[3],gt[2],linewidth=5,edgecolor='g',facecolor='none')\n",
        "ax.add_patch(rect)\n",
        "\n",
        "# showing all the boxes with IoU > 0.5\n",
        "for i in idx:\n",
        "  rect = patches.Rectangle((centres[i][1]-hw[i,1]/2,centres[i][0]-hw[i,0]/2),hw[i,1],hw[i,0],linewidth=1,edgecolor='r',facecolor='none')\n",
        "  ax.add_patch(rect)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nI7mXjS8zA9",
        "outputId": "f461fad5-a72f-4a77-92f5-30653c5209a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(TensorSpec(shape=(224, 224, 3), dtype=tf.float64, name=None), TensorSpec(shape=(3150, 5), dtype=tf.float64, name=None))\n",
            "(TensorSpec(shape=(224, 224, 3), dtype=tf.float64, name=None), TensorSpec(shape=(3150, 5), dtype=tf.float64, name=None))\n"
          ]
        }
      ],
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y))\n",
        "print(train_dataset.element_spec)\n",
        "print(test_dataset.element_spec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "oyX8dnwQ8_1k"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 10\n",
        "SHUFFLE_BUFFER_SIZE = 60\n",
        "\n",
        "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE,drop_remainder=True)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE,drop_remainder=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EeBg_g29GLU"
      },
      "source": [
        "LOSS FUNCTION<br>\n",
        "Hard negative mining hasn't been done here<br>\n",
        "Initial idea was to assign weights to background classes, but there is some problem in that approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "rMEpljzd9CxT"
      },
      "outputs": [],
      "source": [
        "# label is not required here in the standard implementation\n",
        "# calculate the smooth L1 loss\n",
        "def smoothL1(x,y,label):\n",
        "  diff = K.abs(x-y) #* K.switch(label == 10, label*1.0/BOXES, label)\n",
        "  result = K.switch(diff < 1, 0.5 * diff**2, diff - 0.5)\n",
        "  return K.mean(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "8fSUhh8O_DsK"
      },
      "outputs": [],
      "source": [
        "def confidenceLoss(y,label):\n",
        "  unweighted_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(label, y)\n",
        "  # class_weights = tf.constant([[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0/BOXES]]*BOXES])\n",
        "  # weights = tf.reduce_sum(class_weights * y, axis = -1)\n",
        "  # weighted_loss = unweighted_loss * weights\n",
        "  return K.mean(unweighted_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "gn0xh6OX_BvN"
      },
      "outputs": [],
      "source": [
        "def Loss(gt,y):\n",
        "  # shape of y is n * BOXES * output_channels\n",
        "  # shape of gt is n * BOXES * 5 \n",
        "  loss = 0\n",
        "  # localisation loss\n",
        "  loss += smoothL1(y[:,:,-4:],gt[:,:,-4:],gt[:,:,0:1])\n",
        "  # confidence loss\n",
        "  loss += confidenceLoss(y[:,:,:-4],tf.cast(gt[:,:,0],tf.int32))\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8_O3V8DB_Gk",
        "outputId": "51c74056-5226-45a7-cf70-fa004d203946"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/poornimadevikr/git/mymodels/MobileNetv2-SSD/.venvssd/lib/python3.7/site-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "base_learning_rate = 0.001\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),loss=Loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Z7pp6Fp9DDWm",
        "outputId": "39ca0340-fe39-4016-da7d-1ca95148010b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-03 11:15:25.016961: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-03-03 11:15:27.098255: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 722534400 exceeds 10% of free system memory.\n",
            "2025-03-03 11:15:31.303063: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 722534400 exceeds 10% of free system memory.\n",
            "2025-03-03 11:15:36.719505: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 722534400 exceeds 10% of free system memory.\n",
            "2025-03-03 11:15:42.032920: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 722534400 exceeds 10% of free system memory.\n",
            "2025-03-03 11:15:45.248757: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 722534400 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 60 steps, validate on 10 steps\n",
            "Epoch 1/25\n",
            "60/60 [==============================] - ETA: 0s - batch: 29.5000 - size: 1.0000 - loss: 0.4169"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/poornimadevikr/git/mymodels/MobileNetv2-SSD/.venvssd/lib/python3.7/site-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "60/60 [==============================] - 48s 750ms/step - batch: 29.5000 - size: 1.0000 - loss: 0.4169 - val_loss: 0.3378\n",
            "Epoch 2/25\n",
            "60/60 [==============================] - 43s 714ms/step - batch: 29.5000 - size: 1.0000 - loss: 0.1282 - val_loss: 0.0581\n",
            "Epoch 3/25\n",
            "60/60 [==============================] - 42s 707ms/step - batch: 29.5000 - size: 1.0000 - loss: 0.0552 - val_loss: 0.0511\n",
            "Epoch 4/25\n",
            "60/60 [==============================] - 42s 701ms/step - batch: 29.5000 - size: 1.0000 - loss: 0.0461 - val_loss: 0.0414\n",
            "Epoch 5/25\n",
            "60/60 [==============================] - 42s 696ms/step - batch: 29.5000 - size: 1.0000 - loss: 0.0472 - val_loss: 0.0360\n",
            "Epoch 6/25\n",
            "60/60 [==============================] - 42s 701ms/step - batch: 29.5000 - size: 1.0000 - loss: 0.0226 - val_loss: 0.0256\n",
            "Epoch 7/25\n",
            "60/60 [==============================] - 43s 709ms/step - batch: 29.5000 - size: 1.0000 - loss: 0.0291 - val_loss: 0.0227\n",
            "Epoch 8/25\n",
            "60/60 [==============================] - 42s 699ms/step - batch: 29.5000 - size: 1.0000 - loss: 0.0348 - val_loss: 0.0281\n",
            "Epoch 9/25\n",
            "60/60 [==============================] - 41s 687ms/step - batch: 29.5000 - size: 1.0000 - loss: 0.0330 - val_loss: 0.0182\n",
            "Epoch 10/25\n",
            "60/60 [==============================] - 42s 693ms/step - batch: 29.5000 - size: 1.0000 - loss: 0.0196 - val_loss: 0.1360\n",
            "Epoch 11/25\n",
            "60/60 [==============================] - 42s 694ms/step - batch: 29.5000 - size: 1.0000 - loss: 0.0158 - val_loss: 0.0150\n",
            "Epoch 12/25\n",
            "60/60 [==============================] - 42s 701ms/step - batch: 29.5000 - size: 1.0000 - loss: 0.0169 - val_loss: 0.0152\n",
            "Epoch 13/25\n",
            "60/60 [==============================] - 42s 695ms/step - batch: 29.5000 - size: 1.0000 - loss: 0.0196 - val_loss: 0.0130\n",
            "Epoch 14/25\n",
            "60/60 [==============================] - 41s 682ms/step - batch: 29.5000 - size: 1.0000 - loss: 0.0151 - val_loss: 0.3059\n",
            "Epoch 15/25\n",
            "60/60 [==============================] - 41s 687ms/step - batch: 29.5000 - size: 1.0000 - loss: 0.0133 - val_loss: 0.0139\n",
            "Epoch 16/25\n",
            "60/60 [==============================] - 41s 686ms/step - batch: 29.5000 - size: 1.0000 - loss: 0.0119 - val_loss: 0.1956\n",
            "Epoch 17/25\n",
            "60/60 [==============================] - 42s 693ms/step - batch: 29.5000 - size: 1.0000 - loss: 0.0098 - val_loss: 0.1670\n",
            "Epoch 18/25\n",
            "60/60 [==============================] - 41s 686ms/step - batch: 29.5000 - size: 1.0000 - loss: 0.0117 - val_loss: 0.2087\n",
            "Epoch 19/25\n",
            "60/60 [==============================] - 41s 692ms/step - batch: 29.5000 - size: 1.0000 - loss: 0.0134 - val_loss: 0.0480\n",
            "Epoch 20/25\n",
            "60/60 [==============================] - 41s 684ms/step - batch: 29.5000 - size: 1.0000 - loss: 0.0171 - val_loss: 0.0511\n",
            "Epoch 21/25\n",
            "60/60 [==============================] - 41s 688ms/step - batch: 29.5000 - size: 1.0000 - loss: 0.0081 - val_loss: 0.0395\n",
            "Epoch 22/25\n",
            "60/60 [==============================] - 42s 693ms/step - batch: 29.5000 - size: 1.0000 - loss: 0.0092 - val_loss: 0.1127\n",
            "Epoch 23/25\n",
            "60/60 [==============================] - 41s 681ms/step - batch: 29.5000 - size: 1.0000 - loss: 0.0183 - val_loss: 0.0136\n",
            "Epoch 24/25\n",
            "60/60 [==============================] - 41s 680ms/step - batch: 29.5000 - size: 1.0000 - loss: 0.0073 - val_loss: 0.0201\n",
            "Epoch 25/25\n",
            "60/60 [==============================] - 41s 691ms/step - batch: 29.5000 - size: 1.0000 - loss: 0.0806 - val_loss: 0.0105\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_dataset,\n",
        "                    epochs=25,\n",
        "                    validation_data = test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "g_n2VfMsg1NT",
        "outputId": "e20fc8d4-968c-4272-9c62-57eeefcee1b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.010489911288022995"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(test_x,test_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oNuY-45SngR"
      },
      "source": [
        "INFERENCE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "VTfYjsyJTEtv"
      },
      "outputs": [],
      "source": [
        "# create some sample data\n",
        "X, Y = convert(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "QPazH1zFTnE4",
        "outputId": "535d81f5-7835-47ce-98a0-6d78bfe13c78"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/poornimadevikr/git/mymodels/MobileNetv2-SSD/.venvssd/lib/python3.7/site-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(100, 3150, 15)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get prediction for one sample\n",
        "y_pred = model.predict(X)\n",
        "y_pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "jrD03dgjcZMO"
      },
      "outputs": [],
      "source": [
        "OBJperCLASS = 10 # get the top 10 results for each class\n",
        "# get the confidence scores (with class values) and delta for the boxes. For each class, the top 10 values are used\n",
        "def infer(Y):\n",
        "  # classes are actually the index into the default boxes\n",
        "  classes = np.zeros((OBJperCLASS,outputChannels-4),dtype=np.uint16)\n",
        "  conf = np.zeros((OBJperCLASS,outputChannels-4))\n",
        "  delta = np.zeros((OBJperCLASS,outputChannels-4,4))\n",
        "  class_predictions = softmax(Y[:,:outputChannels-4],axis=1)\n",
        "  for i in range(outputChannels-4):\n",
        "    classes[:,i] = bottleneck.argpartition(class_predictions[:,i],BOXES-1-10,axis=-1)[-OBJperCLASS:]\n",
        "    conf[:,i] = class_predictions[classes[:,i],i]\n",
        "    delta[:,i] = Y[classes[:,i],outputChannels-4:]\n",
        "  return conf,classes, delta\n",
        "\n",
        "# generate bounding boxes from the inferred outputs\n",
        "def Bbox(confidence,box_idx,delta):\n",
        "  #delta contains delta(cx,cy,h,w)\n",
        "  bbox_centre = np.zeros((OBJperCLASS,outputChannels-4,2))\n",
        "  bbox_hw = np.zeros((OBJperCLASS,outputChannels-4,2))\n",
        "  for i in range(OBJperCLASS):\n",
        "    bbox_centre[i,:,0] = centres[box_idx[i]][:,0]+delta[i,:,0]\n",
        "    bbox_centre[i,:,1] = centres[box_idx[i]][:,1]+delta[i,:,1]\n",
        "    bbox_hw[i,:,0] = hw[box_idx[i]][:,0] + delta[i,:,2]\n",
        "    bbox_hw[i,:,1] = hw[box_idx[i]][:,1]+delta[i,:,3]\n",
        "  return bbox_centre,bbox_hw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "LY7SOlpafX51",
        "outputId": "eef5e296-27f6-46f1-bfeb-422573f1d1e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n",
            "4: Confidence-0.30385076999664307\t\tCentre-[27.4528119  21.57659078] Height,Width-[27.83850428 27.78028056]\n",
            "4: Confidence-0.06713606417179108\t\tCentre-[28.08684529 21.98701155] Height,Width-[28.15705952 28.01558586]\n",
            "4: Confidence-0.6220841407775879\t\tCentre-[30.05581808 21.20543551] Height,Width-[32.03774533 27.87778761]\n",
            "4: Confidence-0.09897946566343307\t\tCentre-[27.61799747 21.69880056] Height,Width-[27.8048715  30.22098433]\n",
            "4: Confidence-0.001128854462876916\t\tCentre-[35.04817104 20.41615763] Height,Width-[34.8312864  34.91345915]\n",
            "4: Confidence-0.12542755901813507\t\tCentre-[27.59654137 24.54404092] Height,Width-[30.90878579 30.77082631]\n",
            "4: Confidence-0.19926758110523224\t\tCentre-[27.8586839  18.41986179] Height,Width-[27.60722774 34.37052142]\n",
            "4: Confidence-0.028944864869117737\t\tCentre-[27.40938187 21.33165562] Height,Width-[28.2199839  27.92617561]\n",
            "4: Confidence-0.037270959466695786\t\tCentre-[22.93428493 20.60471362] Height,Width-[31.14605328 31.14885899]\n",
            "4: Confidence-0.25909140706062317\t\tCentre-[27.66548353 20.83052135] Height,Width-[27.48141521 32.49016272]\n",
            "9: Confidence-0.8109290599822998\t\tCentre-[27.40938187 21.33165562] Height,Width-[28.2199839  27.92617561]\n",
            "9: Confidence-0.499233603477478\t\tCentre-[27.59654137 24.54404092] Height,Width-[30.90878579 30.77082631]\n",
            "9: Confidence-0.4041575491428375\t\tCentre-[27.61799747 21.69880056] Height,Width-[27.8048715  30.22098433]\n",
            "9: Confidence-0.7129517793655396\t\tCentre-[28.08684529 21.98701155] Height,Width-[28.15705952 28.01558586]\n",
            "9: Confidence-0.5046857595443726\t\tCentre-[27.4528119  21.57659078] Height,Width-[27.83850428 27.78028056]\n",
            "9: Confidence-0.5089973211288452\t\tCentre-[27.66548353 20.83052135] Height,Width-[27.48141521 32.49016272]\n",
            "9: Confidence-0.42833900451660156\t\tCentre-[27.8586839  18.41986179] Height,Width-[27.60722774 34.37052142]\n",
            "9: Confidence-0.7251116037368774\t\tCentre-[22.93428493 20.60471362] Height,Width-[31.14605328 31.14885899]\n",
            "9: Confidence-0.1629943698644638\t\tCentre-[30.05581808 21.20543551] Height,Width-[32.03774533 27.87778761]\n",
            "9: Confidence-0.006701434962451458\t\tCentre-[35.04817104 20.41615763] Height,Width-[34.8312864  34.91345915]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "r = np.random.randint(TESTSIZE)\n",
        "\n",
        "# top 10 predictions for each class\n",
        "confidence, box_idx, delta = infer(y_pred[r])\n",
        "bbox_centre,bbox_hw = Bbox(confidence, box_idx, delta)\n",
        "\n",
        "im = np.array(Image.fromarray(X[r].astype(np.uint8)))\n",
        "fig,ax = plt.subplots(1)\n",
        "ax.imshow(im)\n",
        "\n",
        "for i in range(outputChannels-4):\n",
        "  # skipping backgrounds\n",
        "  if i == NUM_CLASSES:\n",
        "    continue\n",
        "  color = 'r'\n",
        "  # if a class is mentioned in the ground truth, color the boxes green\n",
        "  if i in Y[r,:,0]:\n",
        "    color = 'g'\n",
        "    print(i)\n",
        "  \n",
        "  # skip all the classes which have low confidence values\n",
        "  if (confidence[:,i] > 0.5).any() or i in Y[r,:,0]:\n",
        "    for k in range(OBJperCLASS):\n",
        "      print(\"{}: Confidence-{}\\t\\tCentre-{} Height,Width-{}\".format(i,confidence[k,i],bbox_centre[k,i],bbox_hw[k,i]))\n",
        "      \n",
        "      # draw bounding box only if confidence scores are high\n",
        "      if confidence[k,i] < 0.5:\n",
        "        continue\n",
        "      x = bbox_centre[k,i,0] - bbox_hw[k,i,0]/2\n",
        "      y = bbox_centre[k,i,1] - bbox_hw[k,i,1]/2\n",
        "      rect = patches.Rectangle((y,x),bbox_hw[k,i,1],bbox_hw[k,i,0],linewidth=1,edgecolor=color,facecolor='none')\n",
        "      ax.add_patch(rect)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z32HPrzihVqN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "current.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venvssd",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
